{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKCq5JoM+arSQ8AK+cu3bU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umersolangi/Nodebook/blob/main/Ml_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Wp6GgA3uq6"
      },
      "outputs": [],
      "source": [
        "!pip install -U langgraph \"langchain[anthropic]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "Fwfk7EIj33fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "_GcUuY7233h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pypdf"
      ],
      "metadata": {
        "id": "k8w2fw7p33kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain  faiss-cpu"
      ],
      "metadata": {
        "id": "A_y7d_cn33mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "qhwcj3Zk33oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADER:\n"
      ],
      "metadata": {
        "id": "MifaGjLP4Q7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n"
      ],
      "metadata": {
        "id": "HqFv9TrU33qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfref = PyPDFLoader(\"/content/my_questions.pdf\")\n",
        "docs = pdfref.load()"
      ],
      "metadata": {
        "id": "zAffEJUo33tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "id": "t5cGmHBF33vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHunking"
      ],
      "metadata": {
        "id": "_hB3OKY24YGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "TextSplitter= RecursiveCharacterTextSplitter(chunk_size=1100,chunk_overlap=250)\n",
        "chunks = TextSplitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "YSww5Rvd33x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-large\")\n",
        "store = InMemoryVectorStore(embeddings)\n",
        "store.add_documents(chunks)"
      ],
      "metadata": {
        "id": "Dq9_mfG633z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END"
      ],
      "metadata": {
        "id": "9Bl_3BaX332W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "def generate_with_source(query, context):\n",
        "    prompt = f\"\"\"\n",
        "    Answer the following question based on the provided context. If the answer comes from the document, mention that it was retrieved from the PDF. If the answer is generated by you (the LLM), mention that it comes from your internal knowledge base.\n",
        "\n",
        "    Question: {query}\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "ZxxVOjLW334w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Answerable(query:int):\n",
        "    results =store.similarity_search(query, k=3)\n",
        "    context = \"\\n\".join([f\"{d.page_content} (Source: {d.metadata.get('source')})\" for d in results])\n",
        "    answer = generate_with_source(query, context)\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "Ad06v0Mg3369"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Ohmâ€™s Law?\"\n",
        "answer = Answerable(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "hi1VWZAK3387"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Define Machine Learning\"\n",
        "answer = Answerable(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "x9ZyE9rC33_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, List\n",
        "from langchain_core.documents import Document\n",
        "import operator\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    question: str\n",
        "    context: Annotated[List[Document], operator.add]\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "Ag8p4Qpz34Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "def retrieve(state: GraphState):\n",
        "    question = state[\"question\"]\n",
        "    results = store.similarity_search(question, k=3)\n",
        "    state[\"context\"] = results\n",
        "    return state\n",
        "\n",
        "def generate(state: GraphState):\n",
        "    question = state[\"question\"]\n",
        "    context = \"\\n\".join([f\"{d.page_content} (Source: {d.metadata.get('source')})\" for d in state[\"context\"]])\n",
        "    answer = generate_with_source(question, context)\n",
        "    state[\"answer\"] = answer\n",
        "    return state"
      ],
      "metadata": {
        "id": "kOH2Z1qX4yi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "workflow.add_node(\"retrieve\", retrieve)\n",
        "workflow.add_node(\"generate\", generate)\n",
        "workflow.set_entry_point(\"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"generate\")\n",
        "workflow.set_finish_point(\"generate\")\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "pY5BLjKV4ymJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.invoke()\n"
      ],
      "metadata": {
        "id": "RQsBAgoC44O6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}